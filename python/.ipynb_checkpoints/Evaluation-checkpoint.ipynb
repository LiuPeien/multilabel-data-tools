{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from numpy import genfromtxt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def printResult(y_test, y_predic):\n",
    "    print(metrics.classification_report(y_test, y_predic))\n",
    "    print('HAMMING LOSS: ' + str(metrics.hamming_loss(y_test, y_predic)))\n",
    "    print('ONE-ERROR: ' + str(metrics.zero_one_loss(y_test, y_predic)))\n",
    "    print('COVERAGE: ' + str(metrics.coverage_error(y_test, y_predic)))\n",
    "    print('RANKING LOSS: ' + str(metrics.label_ranking_loss(y_test, y_predic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_data = genfromtxt('E:\\FeatureSelection\\classification\\RankSVM\\yeast5\\\\pretarget.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_data = genfromtxt('E:\\FeatureSelection\\classification\\RankSVM\\yeast5\\\\test_target.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.45      0.57       227\n",
      "          1       0.63      0.46      0.53       315\n",
      "          2       0.67      0.64      0.65       287\n",
      "          3       0.67      0.50      0.57       260\n",
      "          4       0.77      0.43      0.55       221\n",
      "          5       0.56      0.16      0.25       176\n",
      "          6       0.78      0.06      0.10       127\n",
      "          7       0.67      0.01      0.03       155\n",
      "          8       0.00      0.00      0.00        58\n",
      "          9       0.00      0.00      0.00        60\n",
      "         10       0.00      0.00      0.00        71\n",
      "         11       0.77      1.00      0.87       556\n",
      "         12       0.76      1.00      0.86       552\n",
      "         13       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.67      0.58      0.58      3079\n",
      "\n",
      "HAMMING LOSS: 0.19146005509641872\n",
      "ONE-ERROR: 0.805785123967\n",
      "COVERAGE: 11.3815426997\n",
      "RANKING LOSS: 0.438898958512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "printResult(real_data, pre_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
