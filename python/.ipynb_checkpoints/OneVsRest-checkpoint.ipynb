{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import csv\n",
    "\n",
    "def printResult(y_test, y_predic, tactics, algorithm):\n",
    "    print(tactics + ' '+ algorithm)\n",
    "    print(metrics.classification_report(y_test, y_predic))\n",
    "    print('HAMMING LOSS: ' + str(metrics.hamming_loss(y_test, y_predic)))\n",
    "    print('ONE-ERROR: ' + str(metrics.zero_one_loss(y_test, y_predic)))\n",
    "    print('COVERAGE: ' + str(metrics.coverage_error(y_test, y_predic)))\n",
    "    print('RANKING LOSS: ' + str(metrics.label_ranking_loss(y_test, y_predic)))\n",
    "\n",
    "def multilabelClassification(trainfile, testfile = ''):\n",
    "    # read files\n",
    "    # 从两个文件中分别加载训练集和测试集\n",
    "    # X_train, y_train = load_svmlight_file(trainfile, dtype=np.float64, multilabel=True)\n",
    "    # X_test, y_test = load_svmlight_file(testfile, dtype=np.float64, multilabel=True)\n",
    "    # 划分数据集为训练集合测试集\n",
    "    X, y = load_svmlight_file(trainfile, dtype=np.float64, multilabel=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random.randint(1,100))\n",
    "    \n",
    "    mb = MultiLabelBinarizer()\n",
    "    \n",
    "    # transform y into a matrix\n",
    "    y_train = mb.fit_transform(y_train)\n",
    "    y_test = mb.transform(y_test)\n",
    "    \n",
    "    # OneVsRest策略，LogisticRegression分类算法\n",
    "    clf = OneVsRestClassifier(LogisticRegression())\n",
    "#     clf = OneVsRestClassifier(svm.LinearSVC())\n",
    "#     clf = OneVsRestClassifier(tree.DecisionTreeClassifier())\n",
    "#     clf = OneVsRestClassifier(RandomForestClassifier(n_estimators=20))\n",
    "    clf.fit(X_train, y_train)\n",
    "    testY_predic = clf.predict(X_test)\n",
    "    \n",
    "    printResult(y_test, testY_predic, 'OneVsRestClassifier', 'LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainfile = \"C:\\\\Users\\\\Liu Jinhong\\\\Desktop\\\\RVC\\\\rvc.libsvm\"\n",
    "# testfile = \"E:\\\\DataProcess\\\\text\\\\rcv1_1\\\\rcv1_1_test.svm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRestClassifier LogisticRegression\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.04      0.08       252\n",
      "          1       0.89      0.30      0.44       135\n",
      "          2       0.88      0.11      0.19       399\n",
      "          3       1.00      0.03      0.05        79\n",
      "          4       0.96      0.83      0.89      1651\n",
      "          5       0.96      0.80      0.87       911\n",
      "          6       0.96      0.45      0.61       198\n",
      "          7       0.95      0.59      0.73       777\n",
      "          8       0.00      0.00      0.00        25\n",
      "          9       0.94      0.44      0.60       487\n",
      "         10       0.93      0.24      0.39       173\n",
      "         11       0.97      0.49      0.65       135\n",
      "         12       0.00      0.00      0.00        30\n",
      "         13       1.00      0.38      0.55        88\n",
      "         14       0.93      0.51      0.66       570\n",
      "         15       0.92      0.47      0.62       469\n",
      "         16       0.00      0.00      0.00        50\n",
      "         17       0.00      0.00      0.00        84\n",
      "         18       0.88      0.17      0.28       300\n",
      "         19       0.00      0.00      0.00        76\n",
      "         20       0.00      0.00      0.00        29\n",
      "         21       0.86      0.27      0.41       343\n",
      "         22       0.85      0.17      0.28       470\n",
      "         23       1.00      0.11      0.20        64\n",
      "         24       1.00      0.04      0.08        74\n",
      "         25       0.00      0.00      0.00        13\n",
      "         26       0.00      0.00      0.00        24\n",
      "         27       1.00      0.01      0.02       175\n",
      "         28       0.00      0.00      0.00        12\n",
      "         29       0.00      0.00      0.00        40\n",
      "         30       0.97      0.27      0.42       113\n",
      "         31       0.96      0.27      0.42        98\n",
      "         32       0.93      0.28      0.43       142\n",
      "         33       0.95      0.92      0.93      4243\n",
      "         34       1.00      0.23      0.37        92\n",
      "         35       0.84      0.25      0.39       288\n",
      "         36       0.00      0.00      0.00        25\n",
      "         37       1.00      0.28      0.44        71\n",
      "         38       1.00      0.26      0.42        57\n",
      "         39       0.00      0.00      0.00        10\n",
      "         40       0.00      0.00      0.00        32\n",
      "         41       0.00      0.00      0.00         8\n",
      "         42       0.00      0.00      0.00         3\n",
      "         43       0.00      0.00      0.00        16\n",
      "         44       0.96      0.60      0.74       484\n",
      "         45       0.91      0.32      0.48       180\n",
      "         46       0.97      0.62      0.75       311\n",
      "         47       0.00      0.00      0.00        42\n",
      "         48       0.00      0.00      0.00        26\n",
      "         49       0.00      0.00      0.00         1\n",
      "         50       0.00      0.00      0.00         4\n",
      "         51       0.94      0.34      0.50       191\n",
      "         52       0.00      0.00      0.00        24\n",
      "         53       0.93      0.29      0.44       235\n",
      "         54       1.00      0.06      0.11        35\n",
      "         55       0.97      0.20      0.33       154\n",
      "         56       1.00      0.10      0.17        21\n",
      "         57       0.00      0.00      0.00         5\n",
      "         58       1.00      0.73      0.84        55\n",
      "         59       0.93      0.65      0.76      1360\n",
      "         60       0.92      0.59      0.72       189\n",
      "         61       0.80      0.11      0.20        35\n",
      "         62       0.00      0.00      0.00        17\n",
      "         63       0.00      0.00      0.00        24\n",
      "         64       0.96      0.54      0.69        82\n",
      "         65       0.00      0.00      0.00        24\n",
      "         66       0.00      0.00      0.00         4\n",
      "         67       0.00      0.00      0.00         8\n",
      "         68       0.00      0.00      0.00        32\n",
      "         69       0.00      0.00      0.00         3\n",
      "         70       0.96      0.90      0.93      2761\n",
      "         71       0.92      0.50      0.65       386\n",
      "         72       1.00      0.16      0.28        99\n",
      "         73       0.89      0.48      0.62       438\n",
      "         74       1.00      0.21      0.35       108\n",
      "         75       0.00      0.00      0.00        41\n",
      "         76       0.00      0.00      0.00        68\n",
      "         77       0.00      0.00      0.00         5\n",
      "         78       0.64      0.11      0.19        61\n",
      "         79       1.00      0.40      0.57       196\n",
      "         80       0.00      0.00      0.00         2\n",
      "         81       0.00      0.00      0.00         7\n",
      "         82       0.00      0.00      0.00        38\n",
      "         83       0.88      0.54      0.67       651\n",
      "         84       1.00      0.22      0.37        58\n",
      "         85       0.00      0.00      0.00        25\n",
      "         86       0.00      0.00      0.00        17\n",
      "         87       1.00      0.88      0.93       397\n",
      "         88       0.00      0.00      0.00         7\n",
      "         89       0.90      0.58      0.70       390\n",
      "         90       0.87      0.33      0.48       140\n",
      "         91       0.92      0.22      0.36        49\n",
      "         92       0.00      0.00      0.00        24\n",
      "         93       0.98      0.75      0.85       519\n",
      "         94       0.92      0.57      0.70       289\n",
      "         95       0.93      0.78      0.84       583\n",
      "         96       0.93      0.76      0.83       317\n",
      "         97       0.94      0.59      0.73       284\n",
      "         98       0.96      0.83      0.89       923\n",
      "         99       0.96      0.78      0.86       558\n",
      "        100       0.95      0.54      0.69       127\n",
      "        101       0.98      0.63      0.77       209\n",
      "        102       0.96      0.88      0.92      2221\n",
      "\n",
      "avg / total       0.91      0.64      0.72     28875\n",
      "\n",
      "HAMMING LOSS: 0.012307443365695793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE-ERROR: 0.555444444444\n",
      "COVERAGE: 55.8441111111\n",
      "RANKING LOSS: 0.306858405019\n"
     ]
    }
   ],
   "source": [
    "multilabelClassification(trainfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
