{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from numpy import genfromtxt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def printResult(y_test, y_predic):\n",
    "    print(metrics.classification_report(y_test, y_predic))\n",
    "    print('HAMMING LOSS: ' + str(metrics.hamming_loss(y_test, y_predic)))\n",
    "    print('ONE-ERROR: ' + str(metrics.zero_one_loss(y_test, y_predic)))\n",
    "    print('COVERAGE: ' + str(metrics.coverage_error(y_test, y_predic)))\n",
    "    print('RANKING LOSS: ' + str(metrics.label_ranking_loss(y_test, y_predic)))\n",
    "    print('label_ranking_average_precision_score: '+ str(metrics.label_ranking_average_precision_score(y_test, y_predic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_data = genfromtxt('E:\\\\FeatureSelection\\\\classification\\\\ML-kNN\\\\yeast1\\\\pretarget.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1. ...,  1.  1.  0.]\n",
      " [ 0.  0.  0. ...,  1.  1.  0.]\n",
      " [ 1.  1.  0. ...,  1.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1. ...,  1.  1.  0.]\n",
      " [ 0.  0.  1. ...,  1.  1.  0.]\n",
      " [ 0.  0.  0. ...,  1.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(pre_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_data = genfromtxt('E:\\\\FeatureSelection\\\\classification\\\\ML-kNN\\\\yeast1\\\\test_target.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.40      0.53       245\n",
      "          1       0.68      0.27      0.39       333\n",
      "          2       0.63      0.71      0.66       292\n",
      "          3       0.66      0.53      0.59       251\n",
      "          4       0.76      0.47      0.58       197\n",
      "          5       0.55      0.24      0.33       166\n",
      "          6       0.78      0.05      0.10       137\n",
      "          7       0.67      0.04      0.07       156\n",
      "          8       0.00      0.00      0.00        63\n",
      "          9       0.25      0.01      0.03        69\n",
      "         10       0.00      0.00      0.00        75\n",
      "         11       0.73      1.00      0.85       532\n",
      "         12       0.73      1.00      0.84       527\n",
      "         13       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.66      0.57      0.55      3053\n",
      "\n",
      "HAMMING LOSS: 0.20157635467980295\n",
      "ONE-ERROR: 0.83724137931\n",
      "COVERAGE: 11.7765517241\n",
      "RANKING LOSS: 0.465147441502\n",
      "label_ranking_average_precision_score: 0.606398330597\n"
     ]
    }
   ],
   "source": [
    "printResult(real_data, pre_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20157635467980295"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.hamming_loss(real_data, pre_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.label_ranking_loss(np.array([[0, 1], [1, 1]]), np.zeros((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
